{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c86d73a",
   "metadata": {},
   "source": [
    "# HW2 - Speech Enhancement in Reverberant Environments\n",
    "\n",
    "**Q1(a):** Generate Room Impulse Responses (RIRs) and visualize them in the time domain for different reverberation times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16921f3c",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "# Add rir-generator to path\n",
    "sys.path.insert(0, './rir-generator/src')\n",
    "import rir_generator as rir\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e611dc09",
   "metadata": {},
   "source": [
    "## Simulation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Room configuration\n",
    "room_dim = [4.0, 5.0, 3.0]  # meters\n",
    "c = 343.0  # speed of sound (m/s)\n",
    "fs = 16000  # sample rate (Hz)\n",
    "\n",
    "# Reverberation times to test\n",
    "t60_ms_list = [150, 300]  # milliseconds\n",
    "\n",
    "# Microphone array: 5-element ULA along x-axis, centered at [2, 1, 1.7]\n",
    "n_mics = 5\n",
    "d_mic = 0.05  # 5 cm spacing\n",
    "center = np.array([2.0, 1.0, 1.7])\n",
    "\n",
    "# Build mic positions: indices -2, -1, 0, 1, 2\n",
    "mic_positions = []\n",
    "for k in range(-2, 3):\n",
    "    pos = center.copy()\n",
    "    pos[0] += k * d_mic\n",
    "    mic_positions.append(pos)\n",
    "mic_positions = np.array(mic_positions)\n",
    "\n",
    "# Source at 30 degrees, 1.5m from center\n",
    "theta_src = np.deg2rad(30)\n",
    "r_src = 1.5\n",
    "source_pos = np.array([\n",
    "    center[0] + r_src * np.cos(theta_src),\n",
    "    center[1] + r_src * np.sin(theta_src),\n",
    "    center[2]\n",
    "])\n",
    "\n",
    "print(f\"Room: {room_dim} m\")\n",
    "print(f\"Mic array center: {center}\")\n",
    "print(f\"Mic positions (x): {mic_positions[:, 0]}\")\n",
    "print(f\"Source position: {source_pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40135e4",
   "metadata": {},
   "source": [
    "## Generate RIRs for Different T60 Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0269a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate RIRs for each reverberation time\n",
    "rir_dict = {}\n",
    "\n",
    "for t60_ms in t60_ms_list:\n",
    "    t60 = t60_ms / 1000.0  # convert to seconds\n",
    "    n_samples = int(np.ceil(t60 * fs))  # as specified: nsample = T60 * fs\n",
    "    \n",
    "    # Generate RIR using rir_generator\n",
    "    h = rir.generate(\n",
    "        c=c,\n",
    "        fs=fs,\n",
    "        r=mic_positions,\n",
    "        s=source_pos,\n",
    "        L=room_dim,\n",
    "        reverberation_time=t60,\n",
    "        nsample=n_samples\n",
    "    )\n",
    "    rir_dict[t60_ms] = h\n",
    "    print(f\"T60={t60_ms}ms: RIR shape = {h.shape} (samples x mics)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8377282c",
   "metadata": {},
   "source": [
    "## Plot RIRs in Time Domain (First Microphone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56aacb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "for idx, t60_ms in enumerate(t60_ms_list):\n",
    "    h = rir_dict[t60_ms]\n",
    "    h_mic1 = h[:, 0]  # first microphone\n",
    "    t = np.arange(len(h_mic1)) / fs * 1000  # time in ms\n",
    "    \n",
    "    axes[idx].plot(t, h_mic1, linewidth=0.7)\n",
    "    axes[idx].set_xlabel('Time (ms)')\n",
    "    axes[idx].set_ylabel('Amplitude')\n",
    "    axes[idx].set_title(f'RIR - T60 = {t60_ms} ms')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc9ea4",
   "metadata": {},
   "source": [
    "## Q1(b): Generate Measured Signals via Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22289af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as sig\n",
    "import librosa\n",
    "\n",
    "# Load a speech sample from LibriSpeech\n",
    "speech_file = './speech_data/3081-166546-0000.flac'\n",
    "speech, _ = librosa.load(speech_file, sr=fs)\n",
    "\n",
    "print(f\"Speech signal: {len(speech)} samples ({len(speech)/fs:.2f} sec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e95ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolve speech with RIRs to create multichannel \"clean\" reverberant signals\n",
    "clean_signals = {}\n",
    "\n",
    "for t60_ms, h in rir_dict.items():\n",
    "    n_samples_rir, n_mics = h.shape\n",
    "    out_len = len(speech) + n_samples_rir - 1\n",
    "    \n",
    "    # Convolve speech with each mic's RIR\n",
    "    y = np.zeros((n_mics, out_len))\n",
    "    for m in range(n_mics):\n",
    "        y[m] = sig.fftconvolve(speech, h[:, m])\n",
    "    \n",
    "    clean_signals[t60_ms] = y\n",
    "    print(f\"T60={t60_ms}ms: output shape = {y.shape} (mics x samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a9f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot measured signal at first microphone for both T60 values\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 5), sharex=True)\n",
    "\n",
    "for idx, t60_ms in enumerate(t60_ms_list):\n",
    "    y = clean_signals[t60_ms]\n",
    "    t = np.arange(y.shape[1]) / fs\n",
    "    \n",
    "    axes[idx].plot(t, y[0], linewidth=0.5)\n",
    "    axes[idx].set_ylabel('Amplitude')\n",
    "    axes[idx].set_title(f'Reverberant Speech - T60 = {t60_ms} ms (Mic 1)')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39cfe3",
   "metadata": {},
   "source": [
    "## Q1(c): Add Noise to Measured Signals\n",
    "\n",
    "Two noise types:\n",
    "1. **White Gaussian Noise** - spatially and spectrally white\n",
    "2. **Interfering Speaker** - at 150Â°, 2m from array center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f46f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNR levels to test\n",
    "snr_levels = [0, 10]  # dB\n",
    "\n",
    "# Reference microphone for SNR calculation (center mic)\n",
    "ref_mic = 2\n",
    "\n",
    "def scale_noise_to_snr(clean, noise, target_snr_db, ref_mic=2):\n",
    "    \"\"\"Scale noise to achieve target SNR at reference microphone.\"\"\"\n",
    "    p_clean = np.mean(clean[ref_mic] ** 2)\n",
    "    p_noise = np.mean(noise[ref_mic] ** 2)\n",
    "    # SNR = 10*log10(p_clean / p_noise) => p_noise_scaled = p_clean / 10^(SNR/10)\n",
    "    scale = np.sqrt(p_clean / (p_noise * 10 ** (target_snr_db / 10)))\n",
    "    return noise * scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319134cb",
   "metadata": {},
   "source": [
    "### Noise Type 1: White Gaussian Noise (spatially uncorrelated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249bb19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate noisy signals with white Gaussian noise\n",
    "noisy_wgn = {}  # noisy_wgn[t60_ms][snr_db] = (noisy_signal, noise)\n",
    "\n",
    "for t60_ms in t60_ms_list:\n",
    "    noisy_wgn[t60_ms] = {}\n",
    "    clean = clean_signals[t60_ms]\n",
    "    \n",
    "    for snr_db in snr_levels:\n",
    "        # Independent white noise at each mic\n",
    "        noise = np.random.randn(*clean.shape)\n",
    "        noise_scaled = scale_noise_to_snr(clean, noise, snr_db, ref_mic)\n",
    "        noisy = clean + noise_scaled\n",
    "        noisy_wgn[t60_ms][snr_db] = (noisy, noise_scaled)\n",
    "        \n",
    "        print(f\"T60={t60_ms}ms, SNR={snr_db}dB: added WGN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bfca09",
   "metadata": {},
   "source": [
    "### Noise Type 2: Interfering Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedf6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interferer position: 150 degrees, 2m from array center\n",
    "theta_int = np.deg2rad(150)\n",
    "r_int = 2.0\n",
    "interferer_pos = np.array([\n",
    "    center[0] + r_int * np.cos(theta_int),\n",
    "    center[1] + r_int * np.sin(theta_int),\n",
    "    center[2]\n",
    "])\n",
    "\n",
    "# Load a different speech file as interferer\n",
    "interferer_file = './speech_data/5694-64025-0005.flac'\n",
    "interferer_speech, _ = librosa.load(interferer_file, sr=fs)\n",
    "\n",
    "print(f\"Interferer position: {interferer_pos}\")\n",
    "print(f\"Interferer signal: {len(interferer_speech)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100c286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate RIRs for interferer location\n",
    "rir_interferer = {}\n",
    "for t60_ms in t60_ms_list:\n",
    "    t60 = t60_ms / 1000.0\n",
    "    n_samples = int(np.ceil(t60 * fs))\n",
    "    h_int = rir.generate(\n",
    "        c=c, fs=fs, r=mic_positions, s=interferer_pos,\n",
    "        L=room_dim, reverberation_time=t60, nsample=n_samples\n",
    "    )\n",
    "    rir_interferer[t60_ms] = h_int\n",
    "\n",
    "print(\"Generated RIRs for interferer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5beed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_length(x, L):\n",
    "    \"\"\"Zero-pad signal to length L.\"\"\"\n",
    "    if x.shape[1] >= L:\n",
    "        return x[:, :L]\n",
    "    out = np.zeros((x.shape[0], L))\n",
    "    out[:, :x.shape[1]] = x\n",
    "    return out\n",
    "\n",
    "# Generate noisy signals with interfering speaker\n",
    "noisy_interferer = {}  # noisy_interferer[t60_ms][snr_db] = (noisy_signal, interference)\n",
    "\n",
    "for t60_ms in t60_ms_list:\n",
    "    noisy_interferer[t60_ms] = {}\n",
    "    clean = clean_signals[t60_ms]\n",
    "    h_int = rir_interferer[t60_ms]\n",
    "    \n",
    "    # Crop/tile interferer to match target speech length\n",
    "    int_len = len(speech)\n",
    "    if len(interferer_speech) < int_len:\n",
    "        int_sig = np.tile(interferer_speech, int(np.ceil(int_len / len(interferer_speech))))[:int_len]\n",
    "    else:\n",
    "        # Random crop\n",
    "        start = np.random.randint(0, len(interferer_speech) - int_len + 1)\n",
    "        int_sig = interferer_speech[start:start + int_len]\n",
    "    \n",
    "    # Convolve interferer with its RIRs\n",
    "    int_conv = np.zeros((n_mics, int_len + h_int.shape[0] - 1))\n",
    "    for m in range(n_mics):\n",
    "        int_conv[m] = sig.fftconvolve(int_sig, h_int[:, m])\n",
    "    \n",
    "    # Align lengths\n",
    "    max_len = max(clean.shape[1], int_conv.shape[1])\n",
    "    clean_pad = pad_to_length(clean, max_len)\n",
    "    int_pad = pad_to_length(int_conv, max_len)\n",
    "    \n",
    "    for snr_db in snr_levels:\n",
    "        int_scaled = scale_noise_to_snr(clean_pad, int_pad, snr_db, ref_mic)\n",
    "        noisy = clean_pad + int_scaled\n",
    "        noisy_interferer[t60_ms][snr_db] = (noisy, int_scaled)\n",
    "        \n",
    "        print(f\"T60={t60_ms}ms, SNR={snr_db}dB: added interfering speaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacc1a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot example: T60=300ms, SNR=10dB - compare both noise types\n",
    "t60_show = 300\n",
    "snr_show = 10\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 7), sharex=True)\n",
    "\n",
    "clean = clean_signals[t60_show]\n",
    "noisy_w, _ = noisy_wgn[t60_show][snr_show]\n",
    "noisy_i, _ = noisy_interferer[t60_show][snr_show]\n",
    "\n",
    "# Align lengths for plotting\n",
    "max_len = max(clean.shape[1], noisy_w.shape[1], noisy_i.shape[1])\n",
    "t = np.arange(max_len) / fs\n",
    "\n",
    "axes[0].plot(t[:clean.shape[1]], clean[0], linewidth=0.5)\n",
    "axes[0].set_title('Clean Reverberant Signal (Mic 1)')\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "\n",
    "axes[1].plot(t[:noisy_w.shape[1]], noisy_w[0], linewidth=0.5)\n",
    "axes[1].set_title(f'With White Gaussian Noise (SNR = {snr_show} dB)')\n",
    "axes[1].set_ylabel('Amplitude')\n",
    "\n",
    "axes[2].plot(t[:noisy_i.shape[1]], noisy_i[0], linewidth=0.5)\n",
    "axes[2].set_title(f'With Interfering Speaker (SNR = {snr_show} dB)')\n",
    "axes[2].set_ylabel('Amplitude')\n",
    "axes[2].set_xlabel('Time (s)')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ac2136",
   "metadata": {},
   "source": [
    "## Q1(d): Time and Frequency Domain Plots\n",
    "\n",
    "Plot original, clean reverberant, and noisy signals (T60=300ms, SNR=10dB) in both time and frequency domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf438f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_and_spectrum(signal, fs, title):\n",
    "    \"\"\"Plot signal in time domain and its magnitude spectrum.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 3))\n",
    "    \n",
    "    # Time domain\n",
    "    t = np.arange(len(signal)) / fs\n",
    "    axes[0].plot(t, signal, linewidth=0.5)\n",
    "    axes[0].set_xlabel('Time (s)')\n",
    "    axes[0].set_ylabel('Amplitude')\n",
    "    axes[0].set_title(f'{title} - Time Domain')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Frequency domain (magnitude spectrum using Welch's method)\n",
    "    from scipy.signal import welch\n",
    "    freqs, psd = welch(signal, fs=fs, nperseg=1024)\n",
    "    axes[1].semilogy(freqs, psd, linewidth=0.8)\n",
    "    axes[1].set_xlabel('Frequency (Hz)')\n",
    "    axes[1].set_ylabel('PSD')\n",
    "    axes[1].set_title(f'{title} - Power Spectrum')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f4defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for plots\n",
    "t60_plot = 300\n",
    "snr_plot = 10\n",
    "\n",
    "# Get signals\n",
    "original = speech\n",
    "clean_rev = clean_signals[t60_plot][0]  # first mic\n",
    "noisy_wgn_sig, _ = noisy_wgn[t60_plot][snr_plot]\n",
    "noisy_int_sig, _ = noisy_interferer[t60_plot][snr_plot]\n",
    "\n",
    "# Plot each signal\n",
    "plot_time_and_spectrum(original, fs, 'Original (Dry) Signal')\n",
    "plot_time_and_spectrum(clean_rev, fs, 'Clean Reverberant (T60=300ms, Mic 1)')\n",
    "plot_time_and_spectrum(noisy_wgn_sig[0], fs, 'Noisy - White Gaussian (SNR=10dB, Mic 1)')\n",
    "plot_time_and_spectrum(noisy_int_sig[0], fs, 'Noisy - Interfering Speaker (SNR=10dB, Mic 1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc9c0c",
   "metadata": {},
   "source": [
    "## Q1(e): Save Noisy Signals as WAV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76258407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "out_dir = './outputs'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Save noisy signals (first microphone, T60=300ms, SNR=10dB)\n",
    "# Normalize to prevent clipping\n",
    "def normalize(x):\n",
    "    return x / (np.max(np.abs(x)) + 1e-8)\n",
    "\n",
    "sf.write(f'{out_dir}/noisy_wgn_300ms_10dB.wav', normalize(noisy_wgn_sig[0]), fs)\n",
    "sf.write(f'{out_dir}/noisy_interferer_300ms_10dB.wav', normalize(noisy_int_sig[0]), fs)\n",
    "\n",
    "print(f\"Saved WAV files to {out_dir}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
